{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Load from gpt2.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "from src import gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stars(title):\n",
    "    print('='*len(title))\n",
    "    print(title)\n",
    "    print('='*len(title))\n",
    "    \n",
    "def generate_story_from_random_df(df, max_length=100):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    print_stars('Original Caption')\n",
    "    sample_caption = df.sample(1)['0'].values[0]\n",
    "    print(f'\\n{sample_caption}\\n')\n",
    "    \n",
    "    print_stars('Generated Story')\n",
    "    generated_story = gpt2.generate_story(sample_caption, model, max_length=max_length, use_narrative_hook=True)\n",
    "    print(f'\\n{generated_story}\\n')\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print_stars('Time Taken')\n",
    "    print(f'\\nTime taken to generate story: {end - start} seconds\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b6ad8c634349ac8b7043e66eff52af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Image captions\n",
    "df = pd.read_csv(\"img_captions_2000.csv\")\n",
    "model = gpt2.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Original Caption\n",
      "================\n",
      "\n",
      "<start> A newborn giraffe is sitting close to an adult giraffe. <end>\n",
      "\n",
      "===============\n",
      "Generated Story\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "It was the year COVID-19 pandemic finally ended. A newborn giraffe is sitting close to an adult giraffe. It's like \"Hey man, did I get it?\" and we start the next shot of COVID-19 that would have brought us all to my house to meet her.\n",
      "\n",
      "Then we started a search for other humans, but I was really, really excited by what I saw.\n",
      "\n",
      "==========\n",
      "Time Taken\n",
      "==========\n",
      "\n",
      "Time taken to generate story: 7.556862831115723 seconds\n",
      "\n",
      "================\n",
      "Original Caption\n",
      "================\n",
      "\n",
      "<start> A cardboard sign above a pile of limes. <end>\n",
      "\n",
      "===============\n",
      "Generated Story\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "It was the day that led to Earth's last human civilization. A cardboard sign above a pile of limes. We were told the \"Dwarf War had been so rough that we just couldn't stand up\". But, of course, it was the night of the war. \"All the people of the world are here, just as we are. I've been here on time and I don't remember anyone but me here. But that's pretty much how I felt. So I didn't really want to be out of it, that's for sure. You never know.\"\n",
      "\n",
      "\n",
      "Then in March 1967, we did a radio interview with David Rockefeller.\n",
      "\n",
      "==========\n",
      "Time Taken\n",
      "==========\n",
      "\n",
      "Time taken to generate story: 13.034668684005737 seconds\n",
      "\n",
      "================\n",
      "Original Caption\n",
      "================\n",
      "\n",
      "<start> Wine glass sitting on a table with wine in it. <end>\n",
      "\n",
      "===============\n",
      "Generated Story\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'This cannot be happening.' I thought to myself. Wine glass sitting on a table with wine in it. It was an extraordinary feeling.\"\n",
      "\n",
      "\n",
      "\"I know you don't drink alcohol. The last time I drank a drink I went into depression. I have no intention of drinking. Please don't come to me that you don't want to come to me. I know that people think alcohol is better for you. Don't believe it, don't believe it. When I'm a fool I see alcohol as good for me. It doesn't matter; we can't be mad at God. We can't be drunk.\"\n",
      "\n",
      "\n",
      "\"I hate to say it, but you shouldn't be drinking.\"\n",
      "\n",
      "\n",
      "\"A glass is as good as one's life.\"\n",
      "\n",
      "\n",
      "\"Can you imagine how difficult this would have been if I had not asked you to help me? I could have thrown myself to the side but I couldn't see you.\n",
      "\n",
      "==========\n",
      "Time Taken\n",
      "==========\n",
      "\n",
      "Time taken to generate story: 17.11511206626892 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate stories (100, 150, 200 words)\n",
    "\n",
    "story_length = [100, 150, 200]\n",
    "\n",
    "for words in story_length:\n",
    "    generate_story_from_random_df(df, max_length=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Original Caption\n",
      "================\n",
      "\n",
      "<start> a bathroom with a white trash can, toilet, and a white sink. <end>\n",
      "\n",
      "===============\n",
      "Generated Story\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "My neighbor says my cat is threatening to kill me. A bathroom with a white trash can, toilet, and a white sink. My neighbor also says I just need to leave. It's in the laundry and dishes. I can only move about five meters and walk from the door. I can only do it by myself or just use a leash. My neighbor has to go to the toilet so that my cat keeps out of sight. My neighbor says his cat will kill me!\n",
      "\n",
      "==========\n",
      "Time Taken\n",
      "==========\n",
      "\n",
      "Time taken to generate story: 16.609331846237183 seconds\n",
      "\n",
      "================\n",
      "Original Caption\n",
      "================\n",
      "\n",
      "<start> Man putting up umbrella for group of people <end>\n",
      "\n",
      "===============\n",
      "Generated Story\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Don't ask me how, but I remember the day I was born. Man putting up umbrella for group of people at church. I was at their altar, and they're saying, 'Wait a minute, are you trying to be nice?'\"\n",
      "\n",
      "For a week or two, the women and men were standing in front of Christ, on the cross, and praying. \"I think it was really important for me to get involved,\" she says. \"There was a time when I felt really lost. Maybe after coming to a religious society, there was some people who still felt lost. So that's what we went out and said, 'You're being totally inadequate.'\"\n",
      "\n",
      "A group of young girls at the University of Houston.\n",
      "\n",
      "==========\n",
      "Time Taken\n",
      "==========\n",
      "\n",
      "Time taken to generate story: 10.578012943267822 seconds\n",
      "\n",
      "================\n",
      "Original Caption\n",
      "================\n",
      "\n",
      "<start> a tree that has a park bench under it <end>\n",
      "\n",
      "===============\n",
      "Generated Story\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A shrill cry echoed in the mist. A tree that has a park bench under it, and where many trees grow so little that they cannot get access to the park is now, if not completely destroyed, burned to ashes. A young girl, also young, walked along towards the lake. It is one of the places that she could only see from the clouds. She is in her early teens, but she had hoped that she can be there, and that her memories of it would be there when she would return to the village.\n",
      "\n",
      "This is what they see at the lake. It was a city with a city, but the forest there was like nothing but a white mist. The houses were piled on top of each other in half as the forest burned, and the tree that was taller than it sat next to that one. The man on the ground who could bear the pain of the village was in the middle of the forest with her legs still wide open.\n",
      "\n",
      "==========\n",
      "Time Taken\n",
      "==========\n",
      "\n",
      "Time taken to generate story: 16.382866859436035 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate stories (100, 150, 200 words)\n",
    "\n",
    "story_length = [100, 150, 200]\n",
    "\n",
    "for words in story_length:\n",
    "    generate_story_from_random_df(df, max_length=words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries needed**\n",
    "\n",
    "- pip install nltk\n",
    "- pip install textblob\n",
    "- pip install regex\n",
    "- pip install grammarbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "from grammarbot import GrammarBotClient\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Clean Image Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_angular_brackets(text):\n",
    "    '''\n",
    "    Returns text with angular brackets and leading and trailing whitespaces removed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Text to be cleaned and have its angular brackets and leading and trailing whitespaces removed.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    text : str\n",
    "        Cleaned text.\n",
    "    '''\n",
    "    regex = re.compile('<.*?>')\n",
    "    text = re.sub(regex, '', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) Identify Nouns/Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns(text):\n",
    "    blob = TextBlob(text)\n",
    "    noun_phrases = list(blob.noun_phrases)\n",
    "    nouns = [label[0] for label in blob.tags if label[1] in ['NN','NNS'] and not any([label[0] in noun_phrase for noun_phrase in noun_phrases])]\n",
    "    if len(nouns) > 2:\n",
    "        nouns = nouns[:2]\n",
    "    return nouns + noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) Personify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personify(text):\n",
    "    text = re.sub('A person', 'He', text)\n",
    "    text = re.sub('A man', 'He', text)\n",
    "    text = re.sub('A men', 'He', text)\n",
    "    text = re.sub('A woman', 'She', text)\n",
    "    text = re.sub('A women', 'She', text)\n",
    "    text = re.sub('Woman', 'She', text)\n",
    "    text = re.sub('Man', 'He', text)\n",
    "    text = re.sub('A boy', 'The young boy', text)\n",
    "    text = re.sub('A girl', 'The young girl', text)\n",
    "    text = re.sub('A child', 'The child', text)\n",
    "    text = re.sub('Small child', 'The child', text)\n",
    "    text = re.sub('groups of people', 'They', text)\n",
    "    text = re.sub('A group of people', 'They', text)\n",
    "    text = text.capitalize() # Capitalize first word\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iv) Clean Grammatical Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammarbot import GrammarBotClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = GrammarBotClient() # create client beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grammar(paragraph):\n",
    "    '''\n",
    "    Checks and replaces grammatically incorrect parts of paragraph using grammarbot API \n",
    "    (https://github.com/GrammarBot-API/grammarbot-py)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    paragraph : str\n",
    "        Paragraph to be processed and have its grammar corrected.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    paragraph : str\n",
    "        The gramatically correct paragraph processed using grammarbot.\n",
    "    '''\n",
    "    try:\n",
    "        res = client.check(paragraph) \n",
    "        n_text = ''\n",
    "        if res.matches:\n",
    "            match = res.matches[0]\n",
    "            word_start = match.replacement_offset\n",
    "            word_end = match.replacement_offset + match.replacement_length\n",
    "\n",
    "            n_text = paragraph[:word_start] + match.replacements[0] + paragraph[word_end:]\n",
    "            return check_grammar(n_text)\n",
    "        else:\n",
    "            # when res.matches is None, it means the paragraph is already grammatically correct\n",
    "            return paragraph\n",
    "    except:\n",
    "        return paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (v) Story Starters / Narrative Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_narrative_hook():\n",
    "    '''\n",
    "    Returns a random narrative hook that is dramatic.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    text : str\n",
    "        A random narrative hook that is dramatic.\n",
    "    '''\n",
    "    try:\n",
    "        # (i) narrative hooks from datasets online\n",
    "        dramatic = pd.read_csv('../src/hooks.csv')\n",
    "        hook = dramatic.sample(1).opening_line.values[0]\n",
    "    except:\n",
    "        # (ii) default narrative hooks\n",
    "        dramatic = [\"I didn't mean to kill her.\",\n",
    "                    \"A shrill cry echoed in the mist.\",\n",
    "                    \"Don't ask me how, but I remember the day I was born.\",\n",
    "                    \"I still remember the day I died.\",\n",
    "                    \"I still remember how I discovered about my past life.\",\n",
    "                    \"I opened my eyes and had no idea where I was.\",\n",
    "                    \"I had the same dream every night and it was scaring me.\",\n",
    "                    \"'Is this it?' I thought to myself.\",\n",
    "                    \"'This cannot be happening.' I thought to myself.\",\n",
    "                    \"There was a secret meeting tonight.\",\n",
    "                    \"By the time this story ends, five persons' lives will be changed forever, including yours.\",\n",
    "                    \"It was the year of electrocution.\",\n",
    "                    \"It was the year 2020.\",\n",
    "                    \"It was the year humans discovered the secrets laying beneath the ear of the Great Sphinx of Giza.\",\n",
    "                    \"It was the the day that led to Earth's last human civilisation.\",\n",
    "                    \"It was the year COVID-19 pandemic finally ended.\",\n",
    "                    \"It was the day that led to the Moon's crash onto Earth.\",\n",
    "                    \"It was the day that led to Donald Trump's presidency.\",\n",
    "                    \"It was the day that led to the COVID-19 pandemic.\",\n",
    "                    \"It was the day the aliens arrived.\",\n",
    "                    \"I am an inmate at a mental hospital: this is what happens in my mind, every day.\",\n",
    "                    \"I went back in time.\",\n",
    "                    \"I am doing it again, but this time there will be no witnesses.\",\n",
    "                    \"I had never seen a ghost.  But like they say, there is a first time for everything.\",\n",
    "                    \"Am I in heaven?  What happened to me?\",\n",
    "                    \"I couldn't tell if I was in one of my dreams or reality.\",\n",
    "                    \"'You were a key eyewitness to this major accident. Please tell our viewers what you saw.'\",\n",
    "                    \"My neighbour says my cat is threatening to kill me.\",\n",
    "                    \"It was the best of times, it was the worst of times.\",\n",
    "                    \"It was the age of wisdom, it was the age of foolishness.\",\n",
    "                    \"The Earth exhibit is one of the strangest collections of our zoo: 7.59 billion humans and trillions of other biological beings that are totally unaware they are captive and being watched by us.\",\n",
    "                    \"I am never coming back to this place.\",\n",
    "                    \"If you are interested in stories with happy endings, you will be better off reading some other book.\",\n",
    "                    \"Shirley made a wish, and there and then the scene around her changed before her very eyes.\",\n",
    "                    \"It came like a lightning bolt.\",\n",
    "                    \"'Welcome to the good place,' the elder said.\",\n",
    "                    \"'Welcome to the bad place,' the elder said.\",\n",
    "                    \"It’s not my fault.\",\n",
    "                    \"I was not sorry when my brother died.\",\n",
    "                    \"Little did I know how important this witness’s testimony would become.\",\n",
    "                    \"With his heart skipping a beat, Ken switches on his PC simulation.\",\n",
    "                    \"Kit’s voice rang out: 'Nobody moves!'\"]\n",
    "\n",
    "        # Randomnisation because random.choice is not random enough... (prone to recurring pattern)\n",
    "        random_rounds = int(time.time()) % 10\n",
    "        for round in range(random_rounds):\n",
    "            random.shuffle(dramatic)\n",
    "\n",
    "        hook = random.choice(dramatic)\n",
    "    \n",
    "    return hook\n",
    "\n",
    "def embellish_text(input_text):\n",
    "    '''\n",
    "    Embellishes input_text by adding a randomly-selected narrative hook as the opening line\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_text : str\n",
    "        The text to be embellished with a random opening line incorporated\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    text : str\n",
    "        The embellished text with a random opening line incorporated\n",
    "    '''    \n",
    "    return random_narrative_hook() + '\\n\\n' + input_text.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (vi) Convert to paste tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption1 = \"A newborn giraffe is sitting close to an adult giraffe.\" \n",
    "caption2 = \"A cardboard sign above a pile of limes.\"\n",
    "caption3 = \"A bathroom with a white trash can, toilet, and a white sink.\"\n",
    "caption4 = \"Man putting up umbrella for group of people.\"\n",
    "caption5 = \"A large jetliner flying through a clear blue sky.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_verbs(caption):\n",
    "    blob = TextBlob(caption)\n",
    "    for word,tag in blob.tags:\n",
    "        if tag == 'VBG':\n",
    "            word_index = caption.find(word) \n",
    "            # add an 'is' before the present participle found (-ing word)\n",
    "            new_caption =  caption[:word_index] + 'is ' + caption[word_index:]\n",
    "            return new_caption\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_past_tense(caption):\n",
    "    caption = re.sub(r'\\bis\\b', 'was', caption)\n",
    "    caption = re.sub(r'\\bam\\b', 'was', caption)\n",
    "    caption = re.sub(r'\\bare\\b', 'were', caption)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man is walking by his house\n",
      "A man was walking by his house\n"
     ]
    }
   ],
   "source": [
    "caption6 = \"A man is walking by his house\"\n",
    "print(caption6)\n",
    "new_caption = find_verbs(caption6)\n",
    "new_caption = convert_past_tense(new_caption)\n",
    "new_caption = check_grammar(new_caption)\n",
    "print(new_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (vii) Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_incomplete_sentence(paragraph):\n",
    "    '''\n",
    "    Returns the paragraph with its trailing incomplete sentence removed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    paragraph : str\n",
    "        Paragraph to be processed and have its trailing incomplete sentence removed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    paragraph : str\n",
    "        Paragraph with trailing incomplete sentence removed.\n",
    "    '''\n",
    "    # Find negative/reverse position index of last sentence-terminating punctuation in paragraph\n",
    "    last_punctuation_idx = find_last_punctuation_idx(paragraph)\n",
    "\n",
    "    if last_punctuation_idx in [0,1]:\n",
    "        return paragraph\n",
    "    else:\n",
    "        return paragraph[:last_punctuation_idx]\n",
    "\n",
    "    \n",
    "def find_last_punctuation_idx(paragraph):\n",
    "    '''\n",
    "    Identifies and returns the negative/reverse position index of a punctuation symbol (!?,\") that is:\n",
    "    (i) typically indicative of the end of a sentence (\"sentence-terminating\"), and\n",
    "    (ii) closest to the end of the paragraph.\n",
    "\n",
    "    Returns 0 if no such punctuation symbol is present.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    paragraph : str\n",
    "        Paragraph from which the index of the last, sentence-terminating punctuation symbol is to be identified.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    idx : int\n",
    "        The negative/reverse position index of the last, sentence-terminating punctuation symbol in the given paragraph.\n",
    "    '''\n",
    "    # To-do: account for hard cases where sentences ends with single or double quotation marks.\n",
    "    for idx, char in enumerate(paragraph[::-1]):\n",
    "        if char in ['!','.','?']:\n",
    "            return -idx\n",
    "    return 0\n",
    "\n",
    "# Consider removing first sentence from generated paragraph?\n",
    "def remove_first_sentence(text):\n",
    "    first_sentence = sent_tokenize(text)[0]\n",
    "    text = text.lstrip(first_sentence+' ') # Remove first sentence\n",
    "    return text\n",
    "\n",
    "def create_paragraphing_html(text):\n",
    "    '''\n",
    "    Takes a paragraph with line breaks in Python ('\\n') and returns with line breaks in HTML ('<br>')\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Paragraph with line breaks in Python\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    text : str\n",
    "        Paragraph with line breaks in html.\n",
    "    '''\n",
    "    return text.replace('\\n', '<br>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (viii) General Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = GrammarBotClient() # create client beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    '''\n",
    "    Preprocesses input text by \n",
    "    (i) removing angular brackets (if any), \n",
    "    (ii) correcting grammar, and\n",
    "    (iii) capitalising first word.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Text to be preprocessed.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    text : str\n",
    "        Preprocessed text.\n",
    "    '''\n",
    "    # Remove angular brackets\n",
    "    text = remove_angular_brackets(text)\n",
    "\n",
    "    # Converts into past tense\n",
    "    text = find_verbs(text)\n",
    "    text = convert_past_tense(text)\n",
    "\n",
    "    # Correct grammar\n",
    "    text = check_grammar(text)\n",
    "    \n",
    "    # Capitalize\n",
    "    text = text.strip().capitalize()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate paragraph from sentence using GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries needed**\n",
    "- pip install tensorflow==2.3.0\n",
    "- pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAGRAPH-GENERATING MODEL\n",
    "\n",
    "client = GrammarBotClient() # create grammar client beforehand\n",
    "\n",
    "def load_model():\n",
    "    '''\n",
    "    Loads and returns a pre-trained GPT-2 text-generator model (https://huggingface.co/gpt2)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : transformers.pipelines.TextGenerationPipeline\n",
    "        The pre-trained GPT-2 model\n",
    "    '''\n",
    "    model = pipeline('text-generation', model='gpt2')\n",
    "    set_seed(42)\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_story(input_text, model, max_length=100, use_narrative_hook=True):\n",
    "    '''\n",
    "    Returns a story generated using \n",
    "    (i) a pre-trained GPT-2 model, and \n",
    "    (ii) the input text.\n",
    "    \n",
    "    The input text is automatically embellished with a narrative hook incorporated as the opening line.\n",
    "    \n",
    "    The length of generated paragraph may be capped at a given number of words (\"max_length\"), \n",
    "    otherwise the default cap is 100 words.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_text : str\n",
    "        The seed text used to generate a paragraph using GPT-2 model.\n",
    "        It does not need to have a complete sentence.\n",
    "\n",
    "    max_length  : int\n",
    "        Maximum number of words of generated paragraph.\n",
    "        \n",
    "    use_narrative_hook : boolean\n",
    "        Whether to create more dramatic, story-telling impact by adding a randomly-selected narrative hook \n",
    "        as the opening line (i.e before the input_text) before passing such text collectively into the GPT-2 model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    paragraph : str\n",
    "        The paragraph generated using GPT-2 model (inclusive of input text).\n",
    "    '''\n",
    "    # Preprocess\n",
    "    input_text = preprocess(input_text)\n",
    "    if use_narrative_hook:\n",
    "        input_text = embellish_text(input_text)\n",
    "    \n",
    "    # Produce\n",
    "    return generate_paragraph(input_text, model, max_length=max_length)\n",
    "\n",
    "\n",
    "def generate_paragraph(input_text, model, max_length=100):\n",
    "    '''\n",
    "    Returns a paragraph generated using \n",
    "    (i) a pre-trained GPT-2 model, and \n",
    "    (ii) an input text that is incorporated as the opening line.\n",
    "    \n",
    "    The length of generated paragraph may be capped at a given number of words (\"max_length\"), \n",
    "    otherwise the default cap is 50 words.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_text : str\n",
    "        The seed text used to generate a paragraph using GPT-2 model.\n",
    "        It does not need to be a complete sentence, but the text must begin properly.\n",
    "\n",
    "    max_length  : int\n",
    "        Maximum number of words of generated paragraph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    paragraph : str\n",
    "        The paragraph generated using GPT-2 model (inclusive of input text).\n",
    "    '''\n",
    "    # Preprocess\n",
    "    input_text = input_text.capitalize()\n",
    "    \n",
    "    # Produce\n",
    "    paragraph = model(f\"{input_text}\", max_length=max_length, num_return_sequences=1)[0]['generated_text']\n",
    "    paragraph = remove_incomplete_sentence(paragraph)\n",
    "    paragraph = check_grammar(paragraph)\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38493f6e29c946ad8018c3ead00006d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Generate paragraphs using partial sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My dog is very aggressive, she calls me \"Buffy,\" \"She loves me,\" and \"I love her.\" When she says this she says it as if she's describing how much she loves me.\n"
     ]
    }
   ],
   "source": [
    "sample = 'My dog is'\n",
    "print(generate_paragraph(sample, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The secret of life is to have a good relationship with your family, with all people, friends, and family. Everyone has to know something about something that makes you unique. How important it is to get to know you.\n"
     ]
    }
   ],
   "source": [
    "sample = 'The secret of life'\n",
    "print(generate_paragraph(sample, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) Generate paragraphs using captions from TensorFlow Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man in front of a big podium for Team Russia at the team's opening ceremony of this month's IAM World Junior Championship in Japan, was also a major influence on the American rider that earned him the title last season. \n",
      "\n",
      "The person is riding a surfboard in the ocean, so the person may not ride the bike there\"\n",
      "\n",
      "The law does not prevent people from riding on \"surfboards and surfboards. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "captions = [\"man in front of a big podium\",\n",
    "            \"the person is riding a surfboard in the ocean\"]\n",
    "\n",
    "for c in captions:\n",
    "    paragraph = generate_paragraph(c, model)\n",
    "    print(paragraph,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) Generate a profile description based on a person's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Josephine Lin is a member of the U.S. Congress. For more information visit: http://www.congress.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebecca Lim is a writer/founder of The Unsustainable Human Project, a nonprofit that advocates better use of natural and renewable resources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guan King is an international expert on the use of computer systems as \"information systems\"—the same kind of systems that run the computer markets at large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chang Xuan is currently using to move away from the main building.\n",
      "Shaun Tan is set to make his comeback next season for the Jets.\n"
     ]
    }
   ],
   "source": [
    "# Generate profile description based on name\n",
    "\n",
    "names = ['Josephine Lin', 'Rebecca Lim', 'Guan Kiong', 'Chang Xuan', 'Shaun Tan']\n",
    "\n",
    "for name in names:\n",
    "    sentence = generate_paragraph(f\"{name} is\", model, max_length=32)\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iv) Generate STORIES based on image captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import image captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"img_captions_2000.csv\")\n",
    "df['0'] = df['0'].apply(remove_angular_brackets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mass sampling and testing on image captions df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stars(title):\n",
    "    print('='*len(title))\n",
    "    print(title)\n",
    "    print('='*len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story_from_random_df(df):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    print_stars('Original Caption')\n",
    "    sample_caption = df.sample(1)['0'].values[0]\n",
    "    print(f'\\n{sample_caption}\\n')\n",
    "    \n",
    "    print_stars('Generated Story')\n",
    "    generated_story = generate_story(sample_caption, model, max_length=100, use_narrative_hook=True)\n",
    "    print(f'\\n{generated_story}\\n')\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print_stars('Time Taken')\n",
    "    print(f'\\nTime taken to generate story: {end - start} seconds\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Original Caption\n",
      "================\n",
      "\n",
      "A giraffe standing near branches inside an enclosure.\n",
      "\n",
      "===============\n",
      "Generated Story\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "It was the year of electrocution. A giraffe was standing near branches inside an enclosure. The animal began shivering and shaking with pain, and when his eyes locked with white and reddish, he screamed, \"Where are you?! Look!\"\n",
      "\n",
      "There were no witnesses at the scene that day, save one man, who said he was driving his family's two-car truck to work when the giraffe fell on top of him. \"They started screaming and just kept screaming.\n",
      "\n",
      "==========\n",
      "Time Taken\n",
      "==========\n",
      "\n",
      "Time taken to generate story: 5.640526056289673 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_story_from_random_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Original Caption\n",
      "================\n",
      "\n",
      "A woman with a pink umbrella in an alleyway.\n",
      "\n",
      "===============\n",
      "Generated Story\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "It came like a lightning bolt. A woman with a pink umbrella in an alleyway. I saw three of us running. And I said, 'What the hell did she go for?' I can only imagine her being in the building next to me. She screamed and started running toward the entrance.\"\n",
      "\n",
      "She described it as a \"horrifying experience.\n",
      "\n",
      "==========\n",
      "Time Taken\n",
      "==========\n",
      "\n",
      "Time taken to generate story: 9.117458820343018 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_story_from_random_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Original Caption\n",
      "================\n",
      "\n",
      "Bikes are parked next to a stop sign.\n",
      "\n",
      "===============\n",
      "Generated Story\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I opened my eyes and had no idea where I was. Bikes are parked next to a stop sign. I was waiting on traffic and nobody could notice the parking. I looked around and realized I was alone, and I was a bit confused at how long I could wait for traffic.\n",
      "\n",
      "My eyes were on a bus stop and a taxi outside. I knew I had had enough. I grabbed the back bumper and drove the bus home. The lights were out and all was well.\n",
      "\n",
      "==========\n",
      "Time Taken\n",
      "==========\n",
      "\n",
      "Time taken to generate story: 10.77020788192749 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_story_from_random_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate sentence from keyword(s) using Markov Chain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries needed**\n",
    "\n",
    "- pip install nltk\n",
    "\n",
    "- pip install randomsentence\n",
    "<br>(Source: https://github.com/patarapolw/randomsentence)\n",
    "        \n",
    "- Get Brown Corpus\n",
    "<br> (Source: https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/brown.zip)\n",
    "<br><br>Place the zip file into the folder **nltk -> corpora**, and unzip the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from randomsentence.sentence_maker import SentenceMaker\n",
    "from randomsentence.sentence_tools import SentenceTools\n",
    "\n",
    "def generate_sentence_from_keywords(keywords):\n",
    "    '''\n",
    "    Generate sentence from a list of keyword(s) using Markov Chain and Brown Corpus\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    keywords : list of str\n",
    "        A list of keywords from which a sentence is generated using Markov Chain and Brown Corpus\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sentence : str\n",
    "        The generated sentence\n",
    "    '''\n",
    "    sentence_maker = SentenceMaker()\n",
    "    tagged_sentence = sentence_maker.from_keyword_list(keywords)\n",
    "    sentence_tools = SentenceTools()\n",
    "    sentence = sentence_tools.detokenize_tagged(tagged_sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stdbuf was not found; communication with perl may hang due to stdio buffering.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'For pancakes'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence_from_keywords(['pancakes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stdbuf was not found; communication with perl may hang due to stdio buffering.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'She looked out at the baby smile'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence_from_keywords(['baby', 'smile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stdbuf was not found; communication with perl may hang due to stdio buffering.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No, Bari was out of Donald Trump'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence_from_keywords(['Donald Trump'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experiment combining both approaches (\"GPT-2\") and (\"Markov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Note:** Not needed for our purposes, we won't be using Markov to generate sentences\n",
    "- Just an experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stdbuf was not found; communication with perl may hang due to stdio buffering.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He took several large cycling races as a freshman, but didn't go anywhere, but the biggest race in his senior year was the US Open (the final for those two men). \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stdbuf was not found; communication with perl may hang due to stdio buffering.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morgan immediately disposed his sunbathing, but it was soon discovered that he remained asleep on the top of the ladder. Later that same afternoon he awoke to a great shock, being told, to be prepared for the storm. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "keywords = ['cycling', 'sun']\n",
    "\n",
    "for k in keywords:\n",
    "    sentence = generate_sentence_from_keywords([k])\n",
    "    paragraph = generate_paragraph(sentence, model)\n",
    "    print(paragraph,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Narrative Hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Narrative Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random sample of image captions and generate paragraphs using \n",
    "# (i) Markov Chain (on identified entities) + Gpt-2, \n",
    "# (ii) Gpt-2 only.\n",
    "\n",
    "# def generate_and_compare_captions(df):\n",
    "#     for idx, text in enumerate(df.sample(5)[\"0\"].values):\n",
    "#         print(f'({idx+1}) Original text:', text, '\\n')\n",
    "#         nouns = extract_nouns(text)\n",
    "#         sentence = generate_sentence_from_keywords(nouns)\n",
    "#         markov = generate_paragraph(sentence, model, max_length=100)\n",
    "#         print('\\t(i) Markov & GPT-2:', markov, '\\n')\n",
    "#         gpt2 = generate_paragraph(text, model, max_length=100)\n",
    "#         print('\\t(ii) GPT-2 Only:', gpt2, '\\n')\n",
    "#         print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"img_captions_2000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71679d1f1b974d39a21e46d766f35217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Time taken to import library and initiate model: 27.2 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken to generate 1st story (100 words): 9.4 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken to generate 2nd story (150 words): 18.8 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Statistics on run time\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# from src import gpt2\n",
    "\n",
    "# model = gpt2.load_model()\n",
    "    \n",
    "# initiate_model = time.time()\n",
    "    \n",
    "# print(f'\\nTime taken to import library and initiate model: {initiate_model - start:.1f} seconds\\n')\n",
    "\n",
    "# input_text = df.sample(1)['0'].values[0]\n",
    "\n",
    "# gpt2.generate_story(input_text, model, max_length=100, use_narrative_hook=True)\n",
    "\n",
    "# first_attempt = time.time()\n",
    "    \n",
    "# print(f'\\nTime taken to generate 1st story (100 words): {first_attempt - initiate_model:.1f} seconds\\n')\n",
    "\n",
    "# input_text = df.sample(1)['0'].values[0]\n",
    "\n",
    "# gpt2.generate_story(input_text, model, max_length=150, use_narrative_hook=True)\n",
    "\n",
    "# second_attempt = time.time()\n",
    "    \n",
    "# print(f'\\nTime taken to generate 2nd story (150 words): {second_attempt - first_attempt:.1f} seconds\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
